import os
import cv2
import logging
import torch
from ultralytics import YOLO
from pathlib import Path
import json
import subprocess
import shutil

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –ø–æ–∑—ã YOLOv8
MODEL_PATH = "yolov8x-pose.pt"
yolo_model = YOLO(MODEL_PATH)

def process_video(video_name: str, output_name: str, video_folder: str, frame_step="fps"):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ: –¥–µ—Ç–µ–∫—Ü–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""
    try:
        video_path = Path("media") / video_folder / video_name
        output_path = Path("media") / video_folder / output_name
        frames_dir = Path("media") / video_folder / "frames"
        temp_frames_dir = Path("media") / video_folder / "temp_frames"

        # –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        frames_dir.mkdir(exist_ok=True)
        temp_frames_dir.mkdir(exist_ok=True)

        logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –≤–∏–¥–µ–æ: {video_path}")

        cap = cv2.VideoCapture(str(video_path))
        if not cap.isOpened():
            logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ—Ñ–∞–π–ª: {video_path}")
            return None

        fps = int(cap.get(cv2.CAP_PROP_FPS))
        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

        frame_count = 0
        if frame_step == "all":
            step = 1  # –ö–∞–∂–¥—ã–π –∫–∞–¥—Ä
        elif frame_step == "fps":
            step = fps  # –ö–∞–∂–¥—É—é —Å–µ–∫—É–Ω–¥—É
        elif isinstance(frame_step, int) and frame_step > 0:
            step = frame_step  # –ö–∞–∂–¥—ã–π N-–π –∫–∞–¥—Ä
        else:
            logger.warning("‚ö†Ô∏è –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ frame_step, –∏—Å–ø–æ–ª—å–∑—É–µ–º 'fps'")
            step = fps

        processed_frames = 0
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break

            if frame_count % step == 0:
                results = yolo_model(source=frame, conf=0.3, imgsz=640, device='0')
                
                annotated_frame = results[0].plot()
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –∫–∞–¥—Ä –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
                frame_filename = f"frame_{processed_frames:06d}.jpg"
                cv2.imwrite(str(temp_frames_dir / frame_filename), annotated_frame)
                processed_frames += 1

                for result in results:
                    boxes = result.boxes.xyxy.cpu().numpy()
                    
                    for i, (x1, y1, x2, y2) in enumerate(boxes):
                        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])
                        person_crop = frame[y1:y2, x1:x2]

                        if person_crop.size > 0:
                            crop_filename = f"person_{frame_count}_{i}.jpg"
                            cv2.imwrite(str(frames_dir / crop_filename), person_crop)
                            logger.info(f"üßç –í—ã—Ä–µ–∑–∞–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {crop_filename}")

            frame_count += 1

        cap.release()

        # –°–æ–±–∏—Ä–∞–µ–º –≤–∏–¥–µ–æ –∏–∑ –∫–∞–¥—Ä–æ–≤ —Å –ø–æ–º–æ—â—å—é ffmpeg
        try:
            ffmpeg_cmd = [
                'ffmpeg',
                '-framerate', str(fps),
                '-i', str(temp_frames_dir / 'frame_%06d.jpg'),
                '-c:v', 'libx264',
                '-preset', 'medium',
                '-crf', '23',
                '-y',
                str(output_path)
            ]
            logger.info("üé• –°–æ–±–∏—Ä–∞–µ–º –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é ffmpeg...")
            subprocess.run(ffmpeg_cmd, check=True)
            logger.info(f"‚úÖ –í–∏–¥–µ–æ —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–æ: {output_path}")
            return output_name
        except subprocess.CalledProcessError as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ ffmpeg: {e}")
            return None
        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é —Å –∫–∞–¥—Ä–∞–º–∏
            if temp_frames_dir.exists():
                shutil.rmtree(temp_frames_dir)
                logger.info("üßπ –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã —É–¥–∞–ª–µ–Ω—ã")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∏–¥–µ–æ: {e}")
        return None
